{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "Постройте модель на основе полносвязных слоёв для классификации Fashion MNIST из библиотеки torchvision ([datasets](https://pytorch.org/vision/stable/datasets.html)).\n",
    "\n",
    "Получите качество на тестовой выборке не ниже 88%\n",
    "\n",
    "Инструкция по выполнению задания:\n",
    "    Скачайте тренировочную и тестовою часть датасета Fashion MNIST\n",
    "    Постройте модель, выбрав стартовую архитектуру\n",
    "    Обучите модель и сверьте качество на тестовой части с заданным порогом\n",
    "    Изменяйте архитектуру модели пока качество на тестовой части не будет выше порога. Вариации архитектуры можно реализовать через изменение количества слоёв, количества нейронов в слоях и использование регуляризации. Можно использовать различные оптимизаторы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import torch # импортирую основной торч\n",
    "# импортирую библиотеку torchvision для машинного обучения, которая содержит датасеты\n",
    "    # import torchvision as tv # можно так, через карткую запись с \"tv\"\n",
    "import torchvision # буду использовать полную запись\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовка\n",
    "BATCH_SIZE=256 # указываю размер batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаю и подготавливаю тренировочный и тестовы датасеты\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    '.', # указание на директорию, куда скачивать\n",
    "    train=True, # указание на тренировочный датасет \"If True, creates dataset from train-images-idx3-ubyte, otherwise from t10k-images-idx3-ubyte\"\n",
    "    transform=torchvision.transforms.ToTensor(), # преобразование изображений в тензоры\n",
    "    download=True # скачивать надо\n",
    "    )\n",
    "test_dataset = torchvision.datasets.FashionMNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE) # тренировочный датасет\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE) # тестовы датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs=10): # функция обучения модели. её скопировал из лекции, но добавил количество эпох в аргументы\n",
    "    for ep in range(num_epochs): # итерируемся по количеству эпох\n",
    "        train_iters, train_passed  = 0, 0 # для каждой эпохи задаём характеристики обучения, куда будут записываться результаты\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        start=time.time() # фиксируем время начала обучения\n",
    "        \n",
    "        # тренировочный модуль\n",
    "        model.train() # переводим модель в тренировочный режим\n",
    "        for X, y in train: # итерируемся по тренировочной части датасета\n",
    "            trainer.zero_grad() # сбрасываем градиенты\n",
    "            y_pred = model(X) # считаем предсказания модели\n",
    "            l = loss(y_pred, y) # считаем функцию потерь (y - позиция правильного ответа в векторе)\n",
    "            l.backward() # считаем градиенты\n",
    "            trainer.step() # делаем шаг градиентного спуска\n",
    "            train_loss += l.item() # фиксируем количество элементов, которое пропустили через модель\n",
    "            train_acc += (y_pred.argmax(dim=1) == y).sum().item() # фиксируем метрику accuracy. сравниваем позицию максимума в каждом ответе с правильным ответом.\n",
    "                                                                  # суммируем и переводим в скаляр.\n",
    "            train_iters += 1 # количество итераций\n",
    "            train_passed += len(X) # сколько всего данных пропустили через модель\n",
    "        \n",
    "        # тестовый модуль. всё то же самое, кроме сброса и рассчёта градиентов\n",
    "        test_iters, test_passed  = 0, 0\n",
    "        test_loss, test_acc = 0., 0.\n",
    "        model.eval()\n",
    "        for X, y in test:\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            test_loss += l.item()\n",
    "            test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            test_iters += 1\n",
    "            test_passed += len(X)\n",
    "\n",
    "        # печатаем результаты    \n",
    "        print(\"ep: {}, taked: {:.3f}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "            ep, time.time() - start, train_loss / train_iters, train_acc / train_passed,\n",
    "            test_loss / test_iters, test_acc / test_passed)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Попытка 1. Использую самые простые параметры на основании материалов лекции.\n",
    "Захожу с козырей - беру саму эффективную модель и оптимизатор \"adam\" с достаточно маленьким lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель с 3 скрытыми слоями и батч-нормализацией перед функцией активации. в экспериментах на материалах лекции показала самые высокие результаты\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 512),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.ReLU(),    \n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 6.204, train_loss: 0.460247773058871, train_acc: 0.84305, test_loss: 0.3834825411438942, test_acc: 0.8618\n",
      "ep: 1, taked: 6.235, train_loss: 0.3177239336231922, train_acc: 0.8829833333333333, test_loss: 0.36832467671483754, test_acc: 0.8654\n",
      "ep: 2, taked: 6.226, train_loss: 0.27560252781878125, train_acc: 0.89835, test_loss: 0.35442294646054506, test_acc: 0.8691\n",
      "ep: 3, taked: 6.096, train_loss: 0.24404084213236546, train_acc: 0.90975, test_loss: 0.3405782756395638, test_acc: 0.8752\n",
      "ep: 4, taked: 6.205, train_loss: 0.21931247267317264, train_acc: 0.9180333333333334, test_loss: 0.35044979508966206, test_acc: 0.8731\n",
      "ep: 5, taked: 6.169, train_loss: 0.20014272367066524, train_acc: 0.9263333333333333, test_loss: 0.3502777867950499, test_acc: 0.8756\n",
      "ep: 6, taked: 6.110, train_loss: 0.1819811965873901, train_acc: 0.93375, test_loss: 0.34277742379345, test_acc: 0.8812\n",
      "ep: 7, taked: 6.016, train_loss: 0.16807523414175563, train_acc: 0.9381166666666667, test_loss: 0.36763629904016853, test_acc: 0.8752\n",
      "ep: 8, taked: 6.199, train_loss: 0.15446813797697106, train_acc: 0.9435666666666667, test_loss: 0.3749757278943434, test_acc: 0.878\n",
      "ep: 9, taked: 6.181, train_loss: 0.13869561697257327, train_acc: 0.9498833333333333, test_loss: 0.3847170218359679, test_acc: 0.8807\n"
     ]
    }
   ],
   "source": [
    "# настроки функции потерь, оптимизатора и запуск модели\n",
    "loss = torch.nn.CrossEntropyLoss() # функция потерь\n",
    "trainer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "train_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Результат не очень. В какой-то момент accuracy на тестовых данных достигает заданного показателля в 88%, но функция потерь растёт и налицо явное переобучение. Нужно продолжать тренироваться дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Попытка 2. То же, но меняю оптимизатор на SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 5.830, train_loss: 0.14431609719040547, train_acc: 0.9469666666666666, test_loss: 0.3550504838640336, test_acc: 0.8917\n",
      "ep: 1, taked: 5.778, train_loss: 0.13667895583079218, train_acc: 0.9501166666666667, test_loss: 0.34898901914712044, test_acc: 0.893\n",
      "ep: 2, taked: 5.898, train_loss: 0.13190667549980448, train_acc: 0.9517833333333333, test_loss: 0.3449986718886066, test_acc: 0.8935\n",
      "ep: 3, taked: 5.756, train_loss: 0.12842598116778312, train_acc: 0.9532333333333334, test_loss: 0.34207663861452603, test_acc: 0.895\n",
      "ep: 4, taked: 5.781, train_loss: 0.12567516430578332, train_acc: 0.9546666666666667, test_loss: 0.33978704465553167, test_acc: 0.8948\n",
      "ep: 5, taked: 5.850, train_loss: 0.12339214991698874, train_acc: 0.9557, test_loss: 0.33793656177585946, test_acc: 0.8952\n",
      "ep: 6, taked: 5.878, train_loss: 0.12143496175078636, train_acc: 0.95655, test_loss: 0.33638957106741146, test_acc: 0.8959\n",
      "ep: 7, taked: 5.799, train_loss: 0.11972269322326842, train_acc: 0.9571, test_loss: 0.33508005178300665, test_acc: 0.8966\n",
      "ep: 8, taked: 5.785, train_loss: 0.11820550946162102, train_acc: 0.9574166666666667, test_loss: 0.33394749426515774, test_acc: 0.8971\n",
      "ep: 9, taked: 5.756, train_loss: 0.11684432681253616, train_acc: 0.9579166666666666, test_loss: 0.33296554163098335, test_acc: 0.8964\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss() # функция потерь\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=.001)\n",
    "train_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Уже гораздо лучше. Accuracy стабильно выше 88%, функция потерь медленно, но верно продолжает падать.\n",
    "##### В принципе, задание выполнено."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Попытка 3. Расширяю слои и добавляю dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получилось чудовище, которое очень долго обучается, поэтому часть слоёв убрал - ниже закомментировано.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    # torch.nn.Linear(784, 21952),\n",
    "    # torch.nn.BatchNorm1d(21952),\n",
    "    # torch.nn.ReLU(),\n",
    "    # torch.nn.Dropout(0.3),     \n",
    "    # torch.nn.Linear(21952, 10976),\n",
    "    # torch.nn.BatchNorm1d(10976),\n",
    "    # torch.nn.ReLU(),\n",
    "    # torch.nn.Dropout(0.3), \n",
    "    # torch.nn.Linear(10976, 5488),\n",
    "    torch.nn.Linear(784, 5488), # решил попробовать стартовать с этого слоя\n",
    "    torch.nn.BatchNorm1d(5488),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.Linear(5488, 2744),\n",
    "    torch.nn.BatchNorm1d(2744),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.Linear(2744, 1372),\n",
    "    torch.nn.BatchNorm1d(1372),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.Linear(1372, 686),\n",
    "    torch.nn.BatchNorm1d(686),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.Linear(686, 256),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3), \n",
    "    torch.nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 43.834, train_loss: 0.5677300082876328, train_acc: 0.8124, test_loss: 0.44351678937673567, test_acc: 0.8397\n",
      "ep: 1, taked: 40.640, train_loss: 0.4004015198413362, train_acc: 0.85865, test_loss: 0.40568487998098135, test_acc: 0.8511\n",
      "ep: 2, taked: 40.148, train_loss: 0.3575161997308122, train_acc: 0.8727833333333334, test_loss: 0.42818290926516056, test_acc: 0.8386\n",
      "ep: 3, taked: 40.087, train_loss: 0.33379341205383867, train_acc: 0.8815, test_loss: 0.36959649808704853, test_acc: 0.8622\n",
      "ep: 4, taked: 41.911, train_loss: 0.3121816133565091, train_acc: 0.8879833333333333, test_loss: 0.3600862676277757, test_acc: 0.8676\n",
      "ep: 5, taked: 42.552, train_loss: 0.3004648819882819, train_acc: 0.89235, test_loss: 0.36051029302179816, test_acc: 0.8652\n",
      "ep: 6, taked: 42.705, train_loss: 0.2832642280674995, train_acc: 0.89825, test_loss: 0.3502289186231792, test_acc: 0.8751\n",
      "ep: 7, taked: 42.108, train_loss: 0.27086814255156416, train_acc: 0.90345, test_loss: 0.3411148852668703, test_acc: 0.8776\n",
      "ep: 8, taked: 42.546, train_loss: 0.25903614467762887, train_acc: 0.9071833333333333, test_loss: 0.3361895731650293, test_acc: 0.8766\n",
      "ep: 9, taked: 46.479, train_loss: 0.24913470504131724, train_acc: 0.9099833333333334, test_loss: 0.3418471717275679, test_acc: 0.8764\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "train_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Получилось не очень. Целевая accuracy не достигнута."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Попытка 4. То же, но снова меняю оптимизатор на SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 32.762, train_loss: 0.23326570600905316, train_acc: 0.9148333333333334, test_loss: 0.3131233058869839, test_acc: 0.8891\n",
      "ep: 1, taked: 32.380, train_loss: 0.22981907566811177, train_acc: 0.9163166666666667, test_loss: 0.3105848267674446, test_acc: 0.8904\n",
      "ep: 2, taked: 31.906, train_loss: 0.2304696095116595, train_acc: 0.9175, test_loss: 0.30987528720870616, test_acc: 0.8902\n",
      "ep: 3, taked: 30.961, train_loss: 0.2281319041835501, train_acc: 0.9179, test_loss: 0.30962988631799815, test_acc: 0.8907\n",
      "ep: 4, taked: 30.212, train_loss: 0.22473770659020606, train_acc: 0.9195833333333333, test_loss: 0.30886369831860067, test_acc: 0.8903\n",
      "ep: 5, taked: 30.989, train_loss: 0.22758651806953106, train_acc: 0.9191, test_loss: 0.3086301933974028, test_acc: 0.8903\n",
      "ep: 6, taked: 30.132, train_loss: 0.22599609722482397, train_acc: 0.9186, test_loss: 0.3083180967718363, test_acc: 0.8906\n",
      "ep: 7, taked: 30.280, train_loss: 0.22253187127569887, train_acc: 0.9200333333333334, test_loss: 0.30810016924515365, test_acc: 0.8907\n",
      "ep: 8, taked: 29.069, train_loss: 0.22443938686492595, train_acc: 0.9193, test_loss: 0.3077438144013286, test_acc: 0.891\n",
      "ep: 9, taked: 28.955, train_loss: 0.22378456218445555, train_acc: 0.9201666666666667, test_loss: 0.30793135799467564, test_acc: 0.8906\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.SGD(model.parameters(), lr=.001)\n",
    "train_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вообще красота. Accuracy стабильно больше 89%. Значение функции потерь медленно снижается.\n",
    "##### Ниже ставлю эксперимент на 50 эпохах. Эффект примерно такой же функция потерь и accuracy стабилизируются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, taked: 30.268, train_loss: 0.22299631396506694, train_acc: 0.9202166666666667, test_loss: 0.30767538454383614, test_acc: 0.8909\n",
      "ep: 1, taked: 30.469, train_loss: 0.22266264976339137, train_acc: 0.92075, test_loss: 0.30765434904024, test_acc: 0.8906\n",
      "ep: 2, taked: 30.201, train_loss: 0.2238341744592849, train_acc: 0.9205666666666666, test_loss: 0.3076131368987262, test_acc: 0.8907\n",
      "ep: 3, taked: 29.956, train_loss: 0.2231611206810525, train_acc: 0.91965, test_loss: 0.3073070764541626, test_acc: 0.8908\n",
      "ep: 4, taked: 30.141, train_loss: 0.2213785765970007, train_acc: 0.9203833333333333, test_loss: 0.3074204076081514, test_acc: 0.8908\n",
      "ep: 5, taked: 29.998, train_loss: 0.2219564601461938, train_acc: 0.9204833333333333, test_loss: 0.3072748835198581, test_acc: 0.8907\n",
      "ep: 6, taked: 30.493, train_loss: 0.22182581722736358, train_acc: 0.9202666666666667, test_loss: 0.3069695131853223, test_acc: 0.8912\n",
      "ep: 7, taked: 30.069, train_loss: 0.22125112667996832, train_acc: 0.9210833333333334, test_loss: 0.307268582098186, test_acc: 0.891\n",
      "ep: 8, taked: 29.877, train_loss: 0.22058706784501989, train_acc: 0.9212833333333333, test_loss: 0.30670821089297534, test_acc: 0.8916\n",
      "ep: 9, taked: 30.040, train_loss: 0.2217592457507519, train_acc: 0.9202166666666667, test_loss: 0.30679962346330286, test_acc: 0.8909\n",
      "ep: 10, taked: 30.135, train_loss: 0.21996076306764115, train_acc: 0.921, test_loss: 0.3066598266363144, test_acc: 0.8912\n",
      "ep: 11, taked: 30.117, train_loss: 0.2198449877665398, train_acc: 0.9205166666666666, test_loss: 0.306773626152426, test_acc: 0.8913\n",
      "ep: 12, taked: 30.171, train_loss: 0.21997354908826502, train_acc: 0.9207166666666666, test_loss: 0.30681279823184016, test_acc: 0.8915\n",
      "ep: 13, taked: 30.098, train_loss: 0.21941143737194385, train_acc: 0.92165, test_loss: 0.30622729295864703, test_acc: 0.8913\n",
      "ep: 14, taked: 29.901, train_loss: 0.2192892738479249, train_acc: 0.92115, test_loss: 0.3068344848230481, test_acc: 0.8917\n",
      "ep: 15, taked: 30.173, train_loss: 0.21798074359589434, train_acc: 0.9216166666666666, test_loss: 0.30608423752710223, test_acc: 0.8916\n",
      "ep: 16, taked: 30.097, train_loss: 0.22033028108008365, train_acc: 0.9215166666666667, test_loss: 0.3059659763239324, test_acc: 0.8919\n",
      "ep: 17, taked: 29.961, train_loss: 0.21899830438989273, train_acc: 0.9207, test_loss: 0.306040814332664, test_acc: 0.8919\n",
      "ep: 18, taked: 30.074, train_loss: 0.2188165045799093, train_acc: 0.92175, test_loss: 0.30580831030383704, test_acc: 0.8918\n",
      "ep: 19, taked: 30.248, train_loss: 0.2169298566402273, train_acc: 0.92215, test_loss: 0.3058349691331387, test_acc: 0.8919\n",
      "ep: 20, taked: 29.937, train_loss: 0.21859933616633112, train_acc: 0.9221333333333334, test_loss: 0.3058159754611552, test_acc: 0.892\n",
      "ep: 21, taked: 30.099, train_loss: 0.2174937921635648, train_acc: 0.9215333333333333, test_loss: 0.3059329562820494, test_acc: 0.8921\n",
      "ep: 22, taked: 29.920, train_loss: 0.2195264715463557, train_acc: 0.9217666666666666, test_loss: 0.30615553045645355, test_acc: 0.8921\n",
      "ep: 23, taked: 30.036, train_loss: 0.21625991672911543, train_acc: 0.9217833333333333, test_loss: 0.3056532578542829, test_acc: 0.8923\n",
      "ep: 24, taked: 30.019, train_loss: 0.21790057842401747, train_acc: 0.9220833333333334, test_loss: 0.30577844846993685, test_acc: 0.892\n",
      "ep: 25, taked: 30.147, train_loss: 0.21760893774793502, train_acc: 0.9222166666666667, test_loss: 0.30583356246352195, test_acc: 0.8922\n",
      "ep: 26, taked: 30.179, train_loss: 0.21732012952895874, train_acc: 0.9221833333333334, test_loss: 0.3055964944884181, test_acc: 0.8921\n",
      "ep: 27, taked: 30.211, train_loss: 0.2166712019671785, train_acc: 0.9217333333333333, test_loss: 0.3055523542687297, test_acc: 0.892\n",
      "ep: 28, taked: 30.026, train_loss: 0.21774884297492655, train_acc: 0.9226, test_loss: 0.30577474972233176, test_acc: 0.8927\n",
      "ep: 29, taked: 30.481, train_loss: 0.2151836451063765, train_acc: 0.92345, test_loss: 0.30535315880551933, test_acc: 0.8928\n",
      "ep: 30, taked: 30.453, train_loss: 0.21581255555786985, train_acc: 0.92315, test_loss: 0.305063780490309, test_acc: 0.8925\n",
      "ep: 31, taked: 29.873, train_loss: 0.2173761545977694, train_acc: 0.92185, test_loss: 0.3052128515206277, test_acc: 0.8922\n",
      "ep: 32, taked: 30.308, train_loss: 0.21682395824092499, train_acc: 0.9226333333333333, test_loss: 0.3053901452571154, test_acc: 0.8924\n",
      "ep: 33, taked: 29.969, train_loss: 0.21656441983390362, train_acc: 0.9231, test_loss: 0.3050209661945701, test_acc: 0.8925\n",
      "ep: 34, taked: 29.740, train_loss: 0.2149646535515785, train_acc: 0.9228666666666666, test_loss: 0.3048517512157559, test_acc: 0.8922\n",
      "ep: 35, taked: 30.281, train_loss: 0.21651099809306734, train_acc: 0.9219833333333334, test_loss: 0.30538605293259025, test_acc: 0.8928\n",
      "ep: 36, taked: 30.246, train_loss: 0.21752934015177666, train_acc: 0.9223, test_loss: 0.3054147561080754, test_acc: 0.8924\n",
      "ep: 37, taked: 29.968, train_loss: 0.2165780064273388, train_acc: 0.9224666666666667, test_loss: 0.3050873510539532, test_acc: 0.8924\n",
      "ep: 38, taked: 30.284, train_loss: 0.21541685702952934, train_acc: 0.9227666666666666, test_loss: 0.30477038584649563, test_acc: 0.8927\n",
      "ep: 39, taked: 31.154, train_loss: 0.21538260132074355, train_acc: 0.92255, test_loss: 0.30472631519660354, test_acc: 0.8929\n",
      "ep: 40, taked: 30.931, train_loss: 0.21403078706340586, train_acc: 0.9238, test_loss: 0.30496635250747206, test_acc: 0.8932\n",
      "ep: 41, taked: 30.942, train_loss: 0.21592831367507895, train_acc: 0.9226833333333333, test_loss: 0.3049538510851562, test_acc: 0.8929\n",
      "ep: 42, taked: 31.585, train_loss: 0.2145789477736392, train_acc: 0.9229, test_loss: 0.3046797589398921, test_acc: 0.8926\n",
      "ep: 43, taked: 35.285, train_loss: 0.21528279125056368, train_acc: 0.92285, test_loss: 0.3041332168504596, test_acc: 0.8933\n",
      "ep: 44, taked: 29.129, train_loss: 0.21499466464874592, train_acc: 0.92305, test_loss: 0.30397482300177214, test_acc: 0.8929\n",
      "ep: 45, taked: 29.140, train_loss: 0.21480113413739713, train_acc: 0.9231166666666667, test_loss: 0.30429523130878805, test_acc: 0.8931\n",
      "ep: 46, taked: 28.894, train_loss: 0.21370399201169926, train_acc: 0.9240333333333334, test_loss: 0.30462589068338275, test_acc: 0.8935\n",
      "ep: 47, taked: 28.970, train_loss: 0.21382199462423934, train_acc: 0.9234833333333333, test_loss: 0.30443594539538027, test_acc: 0.8928\n",
      "ep: 48, taked: 28.925, train_loss: 0.21399739692185787, train_acc: 0.9224, test_loss: 0.3040706679224968, test_acc: 0.8924\n",
      "ep: 49, taked: 28.938, train_loss: 0.21520212441682815, train_acc: 0.9229166666666667, test_loss: 0.30455088065937164, test_acc: 0.8932\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.SGD(model.parameters(), lr=.001)\n",
    "train_model(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
